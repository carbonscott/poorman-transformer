{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f262f73a570>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poorman_transformer.data                 import TokenManager\n",
    "from poorman_transformer.modeling.transformer import Transformer\n",
    "from poorman_transformer.utils                import init_logger, MetaLog, save_checkpoint, load_checkpoint, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"input.txt\"\n",
    "with open(input_file_path, 'r') as fh:\n",
    "    data = fh.read()\n",
    "token_lib = sorted(list(set(data)))\n",
    "token_manager = TokenManager(token_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "print(''.join(token_lib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" to the people.\\n\\nAll:\\nWe know't,\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[234:234+32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.210497 M parameters\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "token_lib_size = len(token_lib)\n",
    "embd_size      = 64\n",
    "num_blocks     = 4\n",
    "head_size      = 64 // 4\n",
    "context_length = 32\n",
    "num_heads      = embd_size // head_size\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Transformer(token_lib_size, embd_size, context_length, num_blocks, num_heads).to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [[[ USER INPUT ]]]\n",
    "timestamp_prev = \"2023_0822_1233_05\"\n",
    "epoch          = 240\n",
    "\n",
    "drc_chkpt = \"chkpts\"\n",
    "fl_chkpt_prev   = None if timestamp_prev is None else f\"{timestamp_prev}.epoch_{epoch}.chkpt\"\n",
    "path_chkpt_prev = None if fl_chkpt_prev is None else os.path.join(drc_chkpt, fl_chkpt_prev)\n",
    "\n",
    "chkpt = torch.load(path_chkpt_prev)\n",
    "\n",
    "# Load weights...\n",
    "model.module.load_state_dict(chkpt['model_state_dict']) if hasattr(model, 'module') else \\\n",
    "        model.load_state_dict(chkpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___/ Input \\___\n",
      "X-ray\n",
      "\n",
      "___/ Output \\___\n",
      "X-rays there is murderer!\n",
      "\n",
      "GREEN:\n",
      "Speaks, sir, and can become, and tollow,\n",
      "I have mets the senated for his cowardly heart to my lord; thou shalt thou canst\n",
      "What more special as in my father?\n",
      "\n",
      "Bore Servingman:\n",
      "Were it me are article; and for talk with that may letters,\n",
      "into them told, for my dates, where is it murderate,\n",
      "Or keep awhalesome sack here\n",
      "Intend made to grant\n",
      "Hath oken: there crown, something live, her in a thronest.\n",
      "\n",
      "MISTRESS OVENEE:\n",
      "I have made my father neither: we together not thence wi\n"
     ]
    }
   ],
   "source": [
    "input = \"X-ray\"\n",
    "# input = input[:32]\n",
    "input_encoded = token_manager.encode(input[-context_length:])\n",
    "input_encoded = torch.tensor(input_encoded)[None,].to(device)\n",
    "\n",
    "# input_encoded = torch.zeros((1, 1), dtype = torch.long).to(device)\n",
    "\n",
    "print(f\"___/ Input \\___\")\n",
    "print(input)\n",
    "print(\"\")\n",
    "\n",
    "for _ in range(500):\n",
    "    next_token_encoded = model.generate_one(input_encoded[:,-context_length:])\n",
    "    input_encoded = torch.cat([input_encoded, next_token_encoded], dim = 1)\n",
    "\n",
    "\n",
    "output = token_manager.decode(input_encoded.cpu().tolist()[0])\n",
    "print(f\"___/ Output \\___\")\n",
    "print(f\"{output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peaknet-1.0",
   "language": "python",
   "name": "peaknet-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
